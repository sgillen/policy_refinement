{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pybullet_envs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# import panda_gym # Not in requirements, required for panda envs, get latest from here: https://github.com/qgallouedec/panda-gym , don't use version from pypy \n",
    "\n",
    "from seagul.zoo3_utils import load_zoo_agent, ALGOS\n",
    "\n",
    "path_to_zoo = \"/home/asutay/Documents/rl-baselines3-zoo/\" # Very hacky but this is what we do for now. use: git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "\n",
    "#model_dir = os.path.abspath('') + \"/keep_agents/bullet_works_rewards/\" # Bullet envs with mdim and cdim rewards\n",
    "#model_dir = os.path.abspath('') + \"/keep_agents/default_post_01_001/\" # Bullet with no extra reward, just policy refinement with ARS  \n",
    "model_dir = \"/home/asutay/Documents/GitHub/policy_refinement/keep_agents/train_all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/policy_refinement/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through save directory and load everything\n",
    "\n",
    "model_dict = {}\n",
    "env_dict = {}\n",
    "\n",
    "for algo_file in os.scandir(model_dir):\n",
    "    algo_dir = algo_file.path\n",
    "    algo = algo_dir.split(\"/\")[-1]\n",
    "    model_dict[algo] = {}\n",
    "    env_dict[algo] = {}\n",
    "    for env_file in os.scandir(algo_dir):\n",
    "        env_dir = env_file.path\n",
    "        env_name = env_dir.split(\"/\")[-1]\n",
    "        model_dict[algo][env_name] = {}\n",
    "        env_dict[algo][env_name] = {}\n",
    "        env, original_model = load_zoo_agent(env_name, algo, zoo_path = path_to_zoo)\n",
    "        env_dict[algo][env_name] = env\n",
    "        model_dict[algo][env_name]['original'] = original_model\n",
    "        for pkl_file in os.scandir(env_dir):\n",
    "            post_name = pkl_file.path.split(\"/\")[-1].split(\".\")[0]\n",
    "            model_dict[algo][env_name][post_name] = ALGOS[algo].load(pkl_file.path, env=env, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ppo', 'ddpg', 'tqc', 'a2c', 'td3', 'sac']\n",
      "['AntBulletEnv-v0', 'ReacherBulletEnv-v0', 'HopperBulletEnv-v0', 'HalfCheetahBulletEnv-v0', 'Walker2DBulletEnv-v0']\n",
      "['original', 'postprocess_default']\n"
     ]
    }
   ],
   "source": [
    "algo_list = list(model_dict.keys())\n",
    "env_list = list(model_dict[algo_list[0]].keys())\n",
    "post_list = list(model_dict[algo_list[0]][env_list[0]].keys())\n",
    "\n",
    "print(algo_list) # Original Algorithm\n",
    "print(env_list) # Environment\n",
    "\n",
    "# Postprocessor, autogenerated names. \"original\" means the original agent from zoo without additional training, \"postprocess_default\" means just ARS with not extra reward.\n",
    "# Any other name is some new reward functio \n",
    "print(post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_dict['sac']['Walker2DBulletEnv-v0']\n",
    "model = model_dict['sac']['Walker2DBulletEnv-v0'][post_list[0]] #change to post_list[1] for postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from seagul.zoo3_utils import do_rollout_stable\n",
    "def do_rollout_mine(env, model, render=False, render_wait=0.01, seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    if seed:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Add push or something else here \n",
    "\n",
    "        state_list.append(np.copy(obs))\n",
    "        \n",
    "\n",
    "        actions,_ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        # Or maybe here\n",
    "\n",
    "    \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(render_wait)\n",
    "        \n",
    "        act_list.append(np.copy(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    state_arr = np.stack(state_list).squeeze()\n",
    "    act_arr = np.stack(act_list).squeeze()\n",
    "    \n",
    "    return state_arr, act_arr, reward_list, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,act,rew,info = do_rollout_mine(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2298.9702]\n",
      "[{'TimeLimit.truncated': True, 'episode': {'r': 2298.967999, 'l': 1000, 't': 30.066401}, 'terminal_observation': array([-0.30312347,  0.        ,  1.        ,  0.43508393,  0.        ,\n",
      "        0.03084992,  0.        , -0.65845758,  0.75189459,  1.19418287,\n",
      "       -0.04742898, -0.47003978,  1.00226355,  0.03480771,  0.30839986,\n",
      "        0.68590957,  0.38346627, -0.40818453,  1.01035154, -0.00735659,\n",
      "        0.        ,  1.        ,  0.        ])}]\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(rew))\n",
    "print(info)\n",
    "print(type(info))\n",
    "type(info[0]['episode']['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_dict['sac']['Walker2DBulletEnv-v0']\n",
    "model = model_dict['sac']['Walker2DBulletEnv-v0'][post_list[0]] #change to post_list[1] for postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-94c837a2df50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mn_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;31m#Trial number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_trial\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_rollout_mine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mep_rew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mep_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-b649597fd980>\u001b[0m in \u001b[0;36mdo_rollout_mine\u001b[0;34m(env, model, render, render_wait, seed)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Or maybe here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/policy_refinement/lib/python3.6/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/policy_refinement/lib/python3.6/site-packages/stable_baselines3/common/vec_env/vec_normalize.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Normalize the terminal observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Rollout Walker for no noise for n trials\n",
    "env_name = env_list[4]\n",
    "data_no_noise={}\n",
    "row = 0\n",
    "\n",
    "for k in enumerate(post_list):\n",
    "    #for j in enumerate(env_list):\n",
    "        for i in enumerate(algo_list):\n",
    "        \n",
    "            env = env_dict[i[1]][env_name]\n",
    "            model = model_dict[i[1]][env_name][k[1]] # no refinement\n",
    "            #model2 = model_dict[i[1]][j[1]][post_list[1]] # ARS policy refinement\n",
    "            count = 1\n",
    "            fail = 0\n",
    "            rewards_list = []\n",
    "            l_list = [] \n",
    "            n_trial = 300 #Trial number\n",
    "            while count <= n_trial :\n",
    "                obs,act,rew,info = do_rollout_mine(env, model)\n",
    "                ep_rew = info[0]['episode']['r']\n",
    "                ep_l = info[0]['episode']['l']\n",
    "\n",
    "                rewards_list.append(ep_rew)\n",
    "                l_list.append(ep_l)\n",
    "\n",
    "                rewards_arr = np.stack(rewards_list).squeeze()\n",
    "                l_arr = np.stack(l_list).squeeze()\n",
    "\n",
    "                if info[0]['episode']['l']<1000:\n",
    "                    fail+=1\n",
    "                count+=1\n",
    "            fail_percentage = 100*fail/n_trial\n",
    "\n",
    "            reward_mean = np.mean(rewards_arr)\n",
    "            reward_std = np.std(rewards_arr)\n",
    "            l_mean = np.mean(l_arr)\n",
    "#            if k[0] == 1:\n",
    "#                data_no_noise[str(row)] = data_no_noise[str(row)]+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#            else:\n",
    "#                data_no_noise[str(row)] = [j[1],i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            \n",
    "            data_no_noise[str(row)] = [k[1],env_name,i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            print(row)\n",
    "            row += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3333333333333335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env</th>\n",
       "      <th>algo</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>%fail</th>\n",
       "      <th>l_mean</th>\n",
       "      <th>r_mean_refined</th>\n",
       "      <th>r_std_refined</th>\n",
       "      <th>%fail_refined</th>\n",
       "      <th>l_mean_refined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2799.667353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2952.524329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>3488.584792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3638.116329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>3341.984081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3443.095194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>3114.575600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3246.050433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>25.185163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.965402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>8.856911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>16.417330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>11.155703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.163791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>8.638552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>35.280945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2616.276326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2643.144418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2677.904975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2661.941047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2698.035813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2846.292468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2606.001282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2687.876353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2886.417895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2974.621163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>3645.962838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3740.017209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2796.377517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2941.194812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2786.622450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2882.788853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2117.996360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2261.593541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2670.960741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2749.068124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2240.877771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2446.863895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2281.517374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2399.754676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        env algo       r_mean  r_std  %fail  l_mean  \\\n",
       "0           AntBulletEnv-v0  ppo  2799.667353    0.0    0.0  1000.0   \n",
       "1           AntBulletEnv-v0  tqc  3488.584792    0.0    0.0  1000.0   \n",
       "2           AntBulletEnv-v0  td3  3341.984081    0.0    0.0  1000.0   \n",
       "3           AntBulletEnv-v0  sac  3114.575600    0.0    0.0  1000.0   \n",
       "4       ReacherBulletEnv-v0  ppo    25.185163    0.0  100.0   150.0   \n",
       "5       ReacherBulletEnv-v0  tqc     8.856911    0.0  100.0   150.0   \n",
       "6       ReacherBulletEnv-v0  td3    11.155703    0.0  100.0   150.0   \n",
       "7       ReacherBulletEnv-v0  sac     8.638552    0.0  100.0   150.0   \n",
       "8        HopperBulletEnv-v0  ppo  2616.276326    0.0    0.0  1000.0   \n",
       "9        HopperBulletEnv-v0  tqc  2677.904975    0.0    0.0  1000.0   \n",
       "10       HopperBulletEnv-v0  td3  2698.035813    0.0    0.0  1000.0   \n",
       "11       HopperBulletEnv-v0  sac  2606.001282    0.0    0.0  1000.0   \n",
       "12  HalfCheetahBulletEnv-v0  ppo  2886.417895    0.0    0.0  1000.0   \n",
       "13  HalfCheetahBulletEnv-v0  tqc  3645.962838    0.0    0.0  1000.0   \n",
       "14  HalfCheetahBulletEnv-v0  td3  2796.377517    0.0    0.0  1000.0   \n",
       "15  HalfCheetahBulletEnv-v0  sac  2786.622450    0.0    0.0  1000.0   \n",
       "16     Walker2DBulletEnv-v0  ppo  2117.996360    0.0    0.0  1000.0   \n",
       "17     Walker2DBulletEnv-v0  tqc  2670.960741    0.0    0.0  1000.0   \n",
       "18     Walker2DBulletEnv-v0  td3  2240.877771    0.0    0.0  1000.0   \n",
       "19     Walker2DBulletEnv-v0  sac  2281.517374    0.0    0.0  1000.0   \n",
       "\n",
       "    r_mean_refined  r_std_refined  %fail_refined  l_mean_refined  \n",
       "0      2952.524329            0.0            0.0          1000.0  \n",
       "1      3638.116329            0.0            0.0          1000.0  \n",
       "2      3443.095194            0.0            0.0          1000.0  \n",
       "3      3246.050433            0.0            0.0          1000.0  \n",
       "4         1.965402            0.0          100.0           150.0  \n",
       "5        16.417330            0.0          100.0           150.0  \n",
       "6         9.163791            0.0          100.0           150.0  \n",
       "7        35.280945            0.0          100.0           150.0  \n",
       "8      2643.144418            0.0            0.0          1000.0  \n",
       "9      2661.941047            0.0            0.0          1000.0  \n",
       "10     2846.292468            0.0          100.0           994.0  \n",
       "11     2687.876353            0.0          100.0           996.0  \n",
       "12     2974.621163            0.0            0.0          1000.0  \n",
       "13     3740.017209            0.0            0.0          1000.0  \n",
       "14     2941.194812            0.0            0.0          1000.0  \n",
       "15     2882.788853            0.0            0.0          1000.0  \n",
       "16     2261.593541            0.0            0.0          1000.0  \n",
       "17     2749.068124            0.0            0.0          1000.0  \n",
       "18     2446.863895            0.0            0.0          1000.0  \n",
       "19     2399.754676            0.0            0.0          1000.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_no_noise['0'] = data_no_noise['0']+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#print(data_no_noise)\n",
    "import pandas as pd\n",
    "#df=pd.DataFrame.from_dict(data_no_noise, orient='index', columns=['env', 'algo', 'post', 'r_mean', 'r_std', '%fail', 'l_mean'])\n",
    "df_no_noise=pd.DataFrame.from_dict(data_no_noise, orient='index', columns=['env', 'algo', 'r_mean', 'r_std', '%fail', 'l_mean', 'r_mean_refined', 'r_std_refined', '%fail_refined', 'l_mean_refined'])\n",
    "path = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_no_noise.csv'\n",
    "df_no_noise.to_csv(path,index = False)\n",
    "\n",
    "df_no_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original ppo AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original sac AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original sac ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original sac HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original sac HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "original tqc Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "original td3 Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "original sac Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default ppo AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default tqc Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default td3 Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default sac Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define do_rollout with Gaussian noise added to the actions\n",
    "def do_rollout_noise_action(env, model, render=False, render_wait=0.01, seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    if seed:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    l = len(env.action_space.low)\n",
    "    \n",
    "    mean= 0 \n",
    "    std = .025 # actions are normalized between -1 and 1 for all envs so using a static std for noise\n",
    "    while not done:\n",
    "        # Add push or something else here \n",
    "\n",
    "        state_list.append(np.copy(obs))\n",
    "        \n",
    "\n",
    "        actions,_ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        \n",
    "        noise = np.reshape(np.random.normal(mean,std,l),(1,l))\n",
    "        actions += noise #add gaussian noise to actions\n",
    "        \n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        # Or maybe here\n",
    "\n",
    "    \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(render_wait)\n",
    "        \n",
    "        act_list.append(np.copy(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    state_arr = np.stack(state_list).squeeze()\n",
    "    act_arr = np.stack(act_list).squeeze()\n",
    "    \n",
    "    return state_arr, act_arr, reward_list, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define do_rollout with Gaussian noise on the observations\n",
    "def do_rollout_noise_obs(env, model, render=False, render_wait=0.01, seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    if seed:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Add push or something else here \n",
    "\n",
    "        state_list.append(np.copy(obs))\n",
    "        \n",
    "\n",
    "        actions,_ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        mean = 0\n",
    "        std = 1 #to be determined per env\n",
    "        obs += numpy.random.normal(mean,std,1) #sample one value from Gaussian and add to obs\n",
    "        # Or maybe here\n",
    "\n",
    "    \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(render_wait)\n",
    "        \n",
    "        act_list.append(np.copy(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    state_arr = np.stack(state_list).squeeze()\n",
    "    act_arr = np.stack(act_list).squeeze()\n",
    "    \n",
    "    return state_arr, act_arr, reward_list, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Run set number of trials and check fail/fall rate and mean rewards\n",
    "data_noise_action={}\n",
    "row = 0\n",
    "env_name = env_list[4]\n",
    "post_name = ['original', 'refined']\n",
    "for k in enumerate(post_list):\n",
    "    #for j in enumerate(env_list):\n",
    "        for i in enumerate(algo_list):\n",
    "        \n",
    "            env = env_dict[i[1]][env_name]\n",
    "            model = model_dict[i[1]][env_name][k[1]] # no refinement\n",
    "            \n",
    "            count = 1\n",
    "            fail = 0\n",
    "            rewards_list = []\n",
    "            l_list = [] \n",
    "            n_trial = 100 #Trial number\n",
    "            while count <= n_trial :\n",
    "                obs,act,rew,info = do_rollout_noise_action(env, model)\n",
    "                ep_rew = info[0]['episode']['r']\n",
    "                ep_l = info[0]['episode']['l']\n",
    "\n",
    "                rewards_list.append(ep_rew)\n",
    "                l_list.append(ep_l)\n",
    "\n",
    "                rewards_arr = np.stack(rewards_list).squeeze()\n",
    "                l_arr = np.stack(l_list).squeeze()\n",
    "\n",
    "                if info[0]['episode']['l']<1000:\n",
    "                    fail+=1\n",
    "                count+=1\n",
    "            fail_percentage = 100*fail/n_trial\n",
    "\n",
    "            reward_mean = np.mean(rewards_arr)\n",
    "            reward_std = np.std(rewards_arr)\n",
    "            l_mean = np.mean(l_arr)\n",
    "#            if k[0] == 1:\n",
    "#                data_no_noise[str(row)] = data_no_noise[str(row)]+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#            else:\n",
    "#                data_no_noise[str(row)] = [j[1],i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            \n",
    "            data_noise_action[str(row)] = [env_name, post_name[k[0]],i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            print(row)\n",
    "            row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env</th>\n",
       "      <th>refinement</th>\n",
       "      <th>algo</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>%fail</th>\n",
       "      <th>l_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2107.987519</td>\n",
       "      <td>14.649058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>ddpg</td>\n",
       "      <td>1350.828196</td>\n",
       "      <td>721.021668</td>\n",
       "      <td>48.0</td>\n",
       "      <td>697.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2567.735115</td>\n",
       "      <td>497.800045</td>\n",
       "      <td>4.0</td>\n",
       "      <td>962.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>a2c</td>\n",
       "      <td>800.372321</td>\n",
       "      <td>377.609303</td>\n",
       "      <td>21.0</td>\n",
       "      <td>808.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>td3</td>\n",
       "      <td>2195.971525</td>\n",
       "      <td>269.973594</td>\n",
       "      <td>20.0</td>\n",
       "      <td>980.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>sac</td>\n",
       "      <td>2290.710142</td>\n",
       "      <td>17.825047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2223.533503</td>\n",
       "      <td>274.815737</td>\n",
       "      <td>3.0</td>\n",
       "      <td>979.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>ddpg</td>\n",
       "      <td>1858.945893</td>\n",
       "      <td>459.413151</td>\n",
       "      <td>6.0</td>\n",
       "      <td>943.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2810.488674</td>\n",
       "      <td>7.686158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>a2c</td>\n",
       "      <td>948.633275</td>\n",
       "      <td>202.638903</td>\n",
       "      <td>5.0</td>\n",
       "      <td>954.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>td3</td>\n",
       "      <td>2403.173158</td>\n",
       "      <td>10.849095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>999.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>sac</td>\n",
       "      <td>2411.212649</td>\n",
       "      <td>17.874187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     env refinement  algo       r_mean       r_std  %fail  \\\n",
       "0   Walker2DBulletEnv-v0   original   ppo  2107.987519   14.649058    0.0   \n",
       "1   Walker2DBulletEnv-v0   original  ddpg  1350.828196  721.021668   48.0   \n",
       "2   Walker2DBulletEnv-v0   original   tqc  2567.735115  497.800045    4.0   \n",
       "3   Walker2DBulletEnv-v0   original   a2c   800.372321  377.609303   21.0   \n",
       "4   Walker2DBulletEnv-v0   original   td3  2195.971525  269.973594   20.0   \n",
       "5   Walker2DBulletEnv-v0   original   sac  2290.710142   17.825047    2.0   \n",
       "6   Walker2DBulletEnv-v0    refined   ppo  2223.533503  274.815737    3.0   \n",
       "7   Walker2DBulletEnv-v0    refined  ddpg  1858.945893  459.413151    6.0   \n",
       "8   Walker2DBulletEnv-v0    refined   tqc  2810.488674    7.686158    0.0   \n",
       "9   Walker2DBulletEnv-v0    refined   a2c   948.633275  202.638903    5.0   \n",
       "10  Walker2DBulletEnv-v0    refined   td3  2403.173158   10.849095    3.0   \n",
       "11  Walker2DBulletEnv-v0    refined   sac  2411.212649   17.874187    1.0   \n",
       "\n",
       "     l_mean  \n",
       "0   1000.00  \n",
       "1    697.52  \n",
       "2    962.74  \n",
       "3    808.31  \n",
       "4    980.74  \n",
       "5    999.46  \n",
       "6    979.99  \n",
       "7    943.20  \n",
       "8   1000.00  \n",
       "9    954.58  \n",
       "10   999.89  \n",
       "11   999.34  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_no_noise['0'] = data_no_noise['0']+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#print(data_no_noise)\n",
    "import pandas as pd\n",
    "df_action_noise=pd.DataFrame.from_dict(data_noise_action, orient='index', columns=[ 'env', 'refinement', 'algo', 'r_mean', 'r_std', '%fail', 'l_mean'])\n",
    "#df=pd.DataFrame.from_dict(data_noise_action, orient='index', columns=['env', 'algo', 'r_mean', 'r_std', '%fail', 'l_mean', 'r_mean_refined', 'r_std_refined', '%fail_refined', 'l_mean_refined'])\n",
    "path = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_noise_2_5_pct.csv'\n",
    "df_action_noise.to_csv(path,index = False)\n",
    "\n",
    "df_action_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env</th>\n",
       "      <th>refinement</th>\n",
       "      <th>algo</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>%fail</th>\n",
       "      <th>l_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2107.99±14.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>ddpg</td>\n",
       "      <td>1350.83±721.02</td>\n",
       "      <td>48.0</td>\n",
       "      <td>697.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2567.74±497.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>962.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>a2c</td>\n",
       "      <td>800.37±377.61</td>\n",
       "      <td>21.0</td>\n",
       "      <td>808.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>td3</td>\n",
       "      <td>2195.97±269.97</td>\n",
       "      <td>20.0</td>\n",
       "      <td>980.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>original</td>\n",
       "      <td>sac</td>\n",
       "      <td>2290.71±17.83</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2223.53±274.82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>979.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>ddpg</td>\n",
       "      <td>1858.95±459.41</td>\n",
       "      <td>6.0</td>\n",
       "      <td>943.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2810.49±7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>a2c</td>\n",
       "      <td>948.63±202.64</td>\n",
       "      <td>5.0</td>\n",
       "      <td>954.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>td3</td>\n",
       "      <td>2403.17±10.85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>999.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>refined</td>\n",
       "      <td>sac</td>\n",
       "      <td>2411.21±17.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     env refinement  algo          r_mean  %fail   l_mean\n",
       "0   Walker2DBulletEnv-v0   original   ppo   2107.99±14.65    0.0  1000.00\n",
       "1   Walker2DBulletEnv-v0   original  ddpg  1350.83±721.02   48.0   697.52\n",
       "2   Walker2DBulletEnv-v0   original   tqc   2567.74±497.8    4.0   962.74\n",
       "3   Walker2DBulletEnv-v0   original   a2c   800.37±377.61   21.0   808.31\n",
       "4   Walker2DBulletEnv-v0   original   td3  2195.97±269.97   20.0   980.74\n",
       "5   Walker2DBulletEnv-v0   original   sac   2290.71±17.83    2.0   999.46\n",
       "6   Walker2DBulletEnv-v0    refined   ppo  2223.53±274.82    3.0   979.99\n",
       "7   Walker2DBulletEnv-v0    refined  ddpg  1858.95±459.41    6.0   943.20\n",
       "8   Walker2DBulletEnv-v0    refined   tqc    2810.49±7.69    0.0  1000.00\n",
       "9   Walker2DBulletEnv-v0    refined   a2c   948.63±202.64    5.0   954.58\n",
       "10  Walker2DBulletEnv-v0    refined   td3   2403.17±10.85    3.0   999.89\n",
       "11  Walker2DBulletEnv-v0    refined   sac   2411.21±17.87    1.0   999.34"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV from path and format it to merge mean and std \n",
    "# The column names need to be changed according to CSV\n",
    "path_csv = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_noise_2_5_pct.csv'\n",
    "# read csv at path and change the data type of specific columns for rounding\n",
    "df = pd.read_csv(path_csv, dtype =  {'post':str, 'env':str, 'algo':str, 'r_mean':np.double, \n",
    "                                    'r_std':np.double, '%fail':np.double, 'l_mean':np.double} )\n",
    "\n",
    "\n",
    "\n",
    "df_test = df\n",
    "df_test=df_test.round({'r_mean':2,'r_std':2,'%fail':2,'l_mean':2})\n",
    "\n",
    "#merge mean and std with plusminus from this point on the column is type str\n",
    "df_test['r_mean'] = df_test[['r_mean', 'r_std']].astype(str).agg('±'.join, axis=1) \n",
    "\n",
    "#get rid of the std column\n",
    "df_test = df_test.drop('r_std',axis=1)\n",
    "\n",
    "df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\usepackage{booktabs}\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Algo. &  Fall \\% Before &  Fall \\% After \\\\\n",
      "\\midrule\n",
      "  PPO &            0.0 &           3.0 \\\\\n",
      "  TD3 &           20.0 &           3.0 \\\\\n",
      "  SAC &            2.0 &           1.0 \\\\\n",
      "  TQC &            4.0 &           0.0 \\\\\n",
      "  A2C &           21.0 &           5.0 \\\\\n",
      " DDPG &           48.0 &           6.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints the data from in Latex format\n",
    "df_fail = pd.read_csv(path_csv, dtype =  {'env':str, 'algo':str, 'r_mean':np.double, \n",
    "                                    'r_std':np.double, '%fail':np.double, 'l_mean':np.double} )[['algo','refinement','%fail']]\n",
    "\n",
    "df_fail_after = pd.DataFrame()\n",
    "df_fail_after['Fall% After'] = df_fail[df_fail['refinement'] == 'refined']['%fail']\n",
    "s = pd.Series([0,1,2,3,4,5])\n",
    "df_fail_after = df_fail_after.set_index(s)\n",
    "\n",
    "df_fail2 = pd.DataFrame()\n",
    "df_fail2['Algo.'] = df_fail[df_fail['refinement'] == 'original']['algo'].str.upper()\n",
    "df_fail2['Fall % Before'] = df_fail[df_fail['refinement'] == 'original']['%fail']\n",
    "df_fail2['Fall % After'] = df_fail_after\n",
    "\n",
    "b, c, d, e,f = df_fail2.iloc[1].copy(),df_fail2.iloc[2].copy(), df_fail2.iloc[3].copy(),df_fail2.iloc[4].copy(), df_fail2.iloc[5].copy()\n",
    "df_fail2.iloc[1],df_fail2.iloc[2],df_fail2.iloc[3],df_fail2.iloc[4],df_fail2.iloc[5] = e, f, c, d, b \n",
    "df_fail2\n",
    "print(\"\\\\usepackage{booktabs}\\n\"+ df_fail2.to_latex(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (policy_refinement)",
   "language": "python",
   "name": "policy_refinement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
