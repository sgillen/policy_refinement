{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pybullet_envs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# import panda_gym # Not in requirements, required for panda envs, get latest from here: https://github.com/qgallouedec/panda-gym , don't use version from pypy \n",
    "\n",
    "from seagul.zoo3_utils import load_zoo_agent, ALGOS, do_rollout_stable\n",
    "\n",
    "path_to_zoo = \"/home/sgillen/work/external/rl-baselines3-zoo/\" # Very hacky but this is what we do for now. use: git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "\n",
    "model_dir = \"./keep_agents/train_all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ddpg/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ddpg/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ddpg/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ddpg/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ddpg/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ppo/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ppo/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgillen/anaconda3/envs/baselines/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ppo/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ppo/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/ppo/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/sac/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/sac/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/sac/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/sac/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/sac/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/tqc/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/tqc/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/tqc/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/tqc/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/tqc/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/a2c/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/a2c/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/a2c/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/a2c/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/a2c/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/td3/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/td3/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/td3/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/td3/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/sgillen/work/external/rl-baselines3-zoo//rl-trained-agents/td3/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through save directory and load everything\n",
    "\n",
    "model_dict = {}\n",
    "env_dict = {}\n",
    "\n",
    "for algo_file in os.scandir(model_dir):\n",
    "    algo_dir = algo_file.path\n",
    "    algo = algo_dir.split(\"/\")[-1]\n",
    "    model_dict[algo] = {}\n",
    "    env_dict[algo] = {}\n",
    "    for env_file in os.scandir(algo_dir):\n",
    "        env_dir = env_file.path\n",
    "        env_name = env_dir.split(\"/\")[-1]\n",
    "        model_dict[algo][env_name] = {}\n",
    "        env_dict[algo][env_name] = {}\n",
    "        env, original_model = load_zoo_agent(env_name, algo, zoo_path = path_to_zoo)\n",
    "        env_dict[algo][env_name] = env\n",
    "        model_dict[algo][env_name]['original'] = original_model\n",
    "        for pkl_file in os.scandir(env_dir):\n",
    "            post_name = pkl_file.path.split(\"/\")[-1].split(\".\")[0]\n",
    "            model_dict[algo][env_name][post_name] = ALGOS[algo].load(pkl_file.path, env=env, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ddpg', 'ppo', 'sac', 'tqc', 'a2c', 'td3']\n",
      "['Walker2DBulletEnv-v0', 'HalfCheetahBulletEnv-v0', 'AntBulletEnv-v0', 'ReacherBulletEnv-v0', 'HopperBulletEnv-v0']\n",
      "['original', 'postprocess_default']\n"
     ]
    }
   ],
   "source": [
    "algo_list = list(model_dict.keys())\n",
    "env_list = list(model_dict[algo_list[0]].keys())\n",
    "post_list = list(model_dict[algo_list[0]][env_list[0]].keys())\n",
    "\n",
    "print(algo_list) # Original Algorithm\n",
    "print(env_list) # Environment\n",
    "\n",
    "# Postprocessor, autogenerated names. \"original\" means the original agent from zoo without additional training, \"postprocess_default\" means just ARS with not extra reward.\n",
    "# Any other name is some new reward functio \n",
    "print(post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rollout Walker for no noise for n trials\n",
    "env_name = 'Walker2DBulletEnv-v0'\n",
    "data_no_noise={}\n",
    "#row = 0\n",
    "post_name = ['original', 'refined']\n",
    "env_id = 'Walker'\n",
    "for k in enumerate(post_list):\n",
    "    #for j in enumerate(env_list):\n",
    "    row = 0\n",
    "    for i in enumerate(algo_list):\n",
    "\n",
    "        env = env_dict[i[1]][env_name]\n",
    "        model = model_dict[i[1]][env_name][k[1]] # no refinement\n",
    "        #model2 = model_dict[i[1]][j[1]][post_list[1]] # ARS policy refinement\n",
    "        count = 1\n",
    "        fail = 0\n",
    "        rewards_list = []\n",
    "        l_list = [] \n",
    "        n_trial = 300 #Trial number\n",
    "        while count <= n_trial :\n",
    "            obs,act,rew,info = do_rollout_stable(env, model)\n",
    "            ep_rew = info[0]['episode']['r']\n",
    "            ep_l = info[0]['episode']['l']\n",
    "\n",
    "            rewards_list.append(ep_rew)\n",
    "            l_list.append(ep_l)\n",
    "\n",
    "            rewards_arr = np.stack(rewards_list).squeeze()\n",
    "            l_arr = np.stack(l_list).squeeze()\n",
    "\n",
    "            if info[0]['episode']['l']<1000:\n",
    "                fail+=1\n",
    "            count+=1\n",
    "        fail_percentage = 100*fail/n_trial\n",
    "\n",
    "        reward_mean = np.mean(rewards_arr)\n",
    "        reward_std = np.std(rewards_arr)\n",
    "        l_mean = np.mean(l_arr)\n",
    "        if k[0] == 1:\n",
    "            data_no_noise[str(row)] = data_no_noise[str(row)]+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "        else:\n",
    "            data_no_noise[str(row)] = [env_id,i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "\n",
    "        #data_no_noise[str(row)] = [k[1],env_name,i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "        print(row)\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env</th>\n",
       "      <th>algo</th>\n",
       "      <th>fall/100ep before</th>\n",
       "      <th>fail/100ep after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walker</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walker</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Walker</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walker</td>\n",
       "      <td>TD3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walker</td>\n",
       "      <td>SAC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walker</td>\n",
       "      <td>TQC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      env  algo  fall/100ep before  fail/100ep after\n",
       "0  Walker   A2C                0.0               0.0\n",
       "1  Walker   PPO                0.0               0.0\n",
       "2  Walker  DDPG              100.0               0.0\n",
       "3  Walker   TD3                0.0               0.0\n",
       "4  Walker   SAC                0.0               0.0\n",
       "5  Walker   TQC                0.0               0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_no_noise['0'] = data_no_noise['0']+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#print(data_no_noise)\n",
    "import pandas as pd\n",
    "#df=pd.DataFrame.from_dict(data_no_noise, orient='index', columns=['env', 'algo', 'post', 'r_mean', 'r_std', '%fail', 'l_mean'])\n",
    "df_no_noise = pd.DataFrame.from_dict(data_no_noise, orient='index', columns=['env', 'algo', 'r_mean', 'r_std', 'fall/100ep before', 'l_mean', 'r_mean_refined', 'r_std_refined', 'fail/100ep after', 'l_mean_refined'])\n",
    "\n",
    "# Save all as csv\n",
    "df_no_noise['algo'] = df_no_noise['algo'].str.upper()\n",
    "#path = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_no_noise.csv'\n",
    "#df_no_noise.to_csv(path,index = False)\n",
    "\n",
    "# Save just the fall per 100 episode as csv\n",
    "df_no_noise2 = df_no_noise.drop(['r_mean', 'r_std','l_mean', 'r_mean_refined', 'r_std_refined','l_mean_refined'],axis=1)\n",
    "df_no_noise2['algo'] = df_no_noise2['algo'].str.upper()\n",
    "df_no_noise2 = df_no_noise2.round({ 'fall/100ep before':2, 'fall/100ep after':2})\n",
    "a,b, c, d, e,f = df_no_noise2.iloc[0].copy(), df_no_noise2.iloc[1].copy(),df_no_noise2.iloc[2].copy(), df_no_noise2.iloc[3].copy(),df_no_noise2.iloc[4].copy(), df_no_noise2.iloc[5].copy()\n",
    "df_no_noise2.iloc[0],df_no_noise2.iloc[1],df_no_noise2.iloc[2],df_no_noise2.iloc[3],df_no_noise2.iloc[4],df_no_noise2.iloc[5] = c,f,e,a,d,b\n",
    "\n",
    "#path = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_fall_only_no_noise.csv'\n",
    "#df_no_noise2.to_csv(path,index = False)\n",
    "\n",
    "df_no_noise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mujoco 1.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
