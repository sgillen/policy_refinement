{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Box 2D + Mountain Car\n",
    "dfbu = pd.read_csv(\"keep_csv/box2d_all.csv\")[['post', 'config.algo', 'config.env_name', 'ureward_mean', 'ureward_std', 'mdim_mean', 'cdim_mean', 'mdim_nan_mean', 'mdim_std', 'nreward_mean', 'nreward_std', 'len_mean',\n",
    "                             'cdim_nan_mean']]#, 'config.post']]\n",
    "# Bullet envs\n",
    "dfb2 = pd.read_csv(\"keep_csv/train_all.csv\")[['post', 'config.algo', 'config.env_name', 'ureward_mean', 'ureward_std', 'mdim_mean', 'cdim_mean', 'mdim_nan_mean', 'mdim_std', 'nreward_mean', 'nreward_std', 'len_mean',\n",
    "                             'cdim_nan_mean']]#, 'conf\n",
    "\n",
    "df = pd.concat([dfbu, dfb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sort of gross pandas manipulation to get close to the table format we want\n",
    "df2 = pd.DataFrame()\n",
    "env_disp_name = \"Environment\"\n",
    "algo_disp_name = \"Algorithm\"\n",
    "o_disp_name = \"Reward Baseline\"\n",
    "a_disp_name = \"Reward W/ Training\"\n",
    "\n",
    "df2[env_disp_name] = df[df['post'] == 'iden']['config.env_name']\n",
    "df2[algo_disp_name] = df[df['post'] == 'iden']['config.algo']\n",
    "df2['brew_mean'] = df[df['post'] == 'iden']['ureward_mean']\n",
    "df2['brew_std'] = df[df['post'] == 'iden']['ureward_std']\n",
    "df2['arew_mean'] = df[df['post'] == 'postprocess_default']['ureward_mean'].to_numpy()\n",
    "df2['arew_std'] = df[df['post'] == 'postprocess_default']['ureward_std'].to_numpy()\n",
    "\n",
    "df2 = df2.round({'brew_mean':2,'brew_std':1,'arew_mean':2, \"arew_std\":1})\n",
    "df2['brew_mean'] = df2['brew_mean'].astype(int)\n",
    "df2['brew_mean'] = df2[['brew_mean', 'brew_std']].astype(str).agg(' ± '.join, axis=1) \n",
    "df2.drop('brew_std', axis=1, inplace=True)\n",
    "df2['arew_mean'] = df2['arew_mean'].astype(int)\n",
    "df2['arew_mean'] = df2[['arew_mean', 'arew_std']].astype(str).agg(' ± '.join, axis=1) \n",
    "\n",
    "df2.drop('arew_std', axis=1, inplace=True)\n",
    "df2 = df2.rename({'brew_mean':'Baseline Return'}, axis=1)\n",
    "df2 = df2.rename({'arew_mean':'Refined  Return'}, axis=1)\n",
    "\n",
    "env_dict = {}\n",
    "for env in df2['Environment']:\n",
    "    env_dict[env] = 1 \n",
    "\n",
    "df2 = df2.set_index([\"Algorithm\", \"Environment\"]).sort_index()\n",
    "envs = list(env_dict.keys())\n",
    "\n",
    "index_list = []\n",
    "for algo in [\"a2c\",\"ppo\",\"ddpg\",\"td3\",\"sac\",\"tqc\"]:\n",
    "    for env in envs:\n",
    "        index_list.append((algo,env))\n",
    "        \n",
    "df2 = df2.reindex(index_list)# (\"ppo\", envs), (\"ddpg\", envs), (\"td3\",envs), (\"td3\", envs) ,(\"tqc\", envs)])\n",
    "df2 = df2.reset_index()\n",
    "\n",
    "#index = pd.MultiIndex.from_frame(df2)\n",
    "#df2.set_index([\"Algorithm\",\"Environment\"])\n",
    "#df2.set_index(index).drop([\"Environment\", \"Algorithm\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LunarLanderContinuous-v2\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  96 ± 148.3 &  277 ± 23.0 &   247 ± 92.5 &  199 ± 99.4 &  226 ± 103.5 &  280 ± 23.0 \\\\\n",
      "Refined  Return &  208 ± 88.6 &  270 ± 22.3 &  217 ± 149.3 &  259 ± 21.7 &   279 ± 14.0 &  288 ± 17.7 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "BipedalWalker-v3\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  301 ± 1.0 &  207 ± 98.4 &  199 ± 140.0 &  318 ± 2.4 &  261 ± 116.9 &  292 ± 125.1 \\\\\n",
      "Refined  Return &  313 ± 1.1 &   325 ± 1.0 &    291 ± 1.5 &  334 ± 0.6 &    321 ± 1.2 &    344 ± 0.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "BipedalWalkerHardcore-v3\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &   78 ± 109.5 &  131 ± 123.3 &  NaN &  -94 ± 12.7 &  -34 ± 88.8 &  224 ± 101.7 \\\\\n",
      "Refined  Return &  145 ± 100.9 &   131 ± 98.6 &  NaN &   -24 ± 5.3 &   18 ± 69.9 &  243 ± 100.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Pendulum-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  -230 ± 99.2 &  -171 ± 127.4 &  -157 ± 99.3 &  -110 ± 83.5 &  -116 ± 116.1 &  -144 ± 45.9 \\\\\n",
      "Refined  Return &  -229 ± 98.5 &  -149 ± 109.1 &  -152 ± 87.6 &  -110 ± 83.8 &   -101 ± 97.1 &  -144 ± 45.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "MountainCarContinuous-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  91 ± 0.2 &  87 ± 2.8 &  93 ± 0.0 &  93 ± 0.1 &  95 ± 0.6 &  57 ± 47.1 \\\\\n",
      "Refined  Return &  92 ± 0.1 &  99 ± 0.1 &  94 ± 0.3 &  94 ± 0.1 &  95 ± 0.8 &   96 ± 0.7 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Walker2DBulletEnv-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  905 ± 276.4 &  2111 ± 10.8 &  1015 ± 790.5 &  2052 ± 569.0 &  2064 ± 681.3 &  2418 ± 755.8 \\\\\n",
      "Refined  Return &    998 ± 1.7 &  2285 ± 10.5 &   1973 ± 21.4 &   2410 ± 11.8 &   2417 ± 16.7 &    2814 ± 5.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "HalfCheetahBulletEnv-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  2097 ± 38.3 &  2908 ± 38.8 &   2088 ± 95.1 &  2826 ± 14.5 &  2793 ± 8.8 &  3683 ± 17.6 \\\\\n",
      "Refined  Return &  2197 ± 40.4 &  3006 ± 31.1 &  2254 ± 159.0 &  2934 ± 10.2 &  2887 ± 6.6 &   3808 ± 6.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "HopperBulletEnv-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &   768 ± 346.1 &  2537 ± 263.5 &   949 ± 509.3 &  2679 ± 28.5 &  2632 ± 11.9 &  2693 ± 12.6 \\\\\n",
      "Refined  Return &  1502 ± 418.2 &    2639 ± 7.8 &  2240 ± 660.3 &  2801 ± 51.2 &  2720 ± 11.7 &  2775 ± 25.9 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "AntBulletEnv-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &   2514 ± 8.1 &  2883 ± 55.2 &  2394 ± 62.8 &  3313 ± 41.5 &  3096 ± 20.9 &  3418 ± 171.1 \\\\\n",
      "Refined  Return &  2694 ± 13.2 &  2897 ± 46.7 &  2385 ± 80.4 &  3390 ± 13.7 &   3208 ± 9.1 &   3660 ± 16.7 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "ReacherBulletEnv-v0\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Baseline Return &  14 ± 8.5 &  17 ± 8.4 &  16 ± 10.7 &  12 ± 5.6 &  14 ± 11.2 &  15 ± 9.0 \\\\\n",
      "Refined  Return &  14 ± 8.5 &  17 ± 8.0 &  15 ± 11.3 &  12 ± 5.7 &  13 ± 11.2 &  15 ± 9.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print as latex, we manually inserted this with some modifications in formatting to the manuscript\n",
    "for env in env_dict.keys():\n",
    "    dfp = df2[df2['Environment'] == env].drop([\"Algorithm\", \"Environment\"],axis=1,inplace=False).transpose()\n",
    "    print(env)\n",
    "    print(dfp.to_latex(multirow=True, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sgillen/work/external/rl-baselines3-zoo/rl-trained-agents/ddpg/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgillen/anaconda3/envs/baselines/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# Hack for visualizing, can only load one environment / process with rendering. Need to restart NB to change the env\n",
    "model_dir = \"./keep_agents/train_all\"\n",
    "\n",
    "import os\n",
    "from seagul.zoo3_utils import load_zoo_agent, ALGOS, do_rollout_stable\n",
    "import pybullet_envs\n",
    "import gym\n",
    "\n",
    "viz_env = \"Walker2DBulletEnv-v0\"\n",
    "viz_algo = \"ddpg\"\n",
    "model_dict = {}\n",
    "env_dict = {}\n",
    "\n",
    "for algo_file in os.scandir(model_dir):\n",
    "    algo_dir = algo_file.path\n",
    "    algo = algo_dir.split(\"/\")[-1]\n",
    "    if algo == viz_algo:\n",
    "        model_dict[algo] = {}\n",
    "        env_dict[algo] = {}\n",
    "        for env_file in os.scandir(algo_dir):\n",
    "            env_dir = env_file.path\n",
    "            env_name = env_dir.split(\"/\")[-1]\n",
    "            model_dict[algo][env_name] = {}\n",
    "            env_dict[algo][env_name] = {}\n",
    "            if viz_env in env_name:\n",
    "\n",
    "                env, original_model = load_zoo_agent(env_name, algo, render=False, env_kwargs={\"render\":True})\n",
    "                env.close()\n",
    "                env_dict[algo][env_name] = env\n",
    "                model_dict[algo][env_name]['original'] = original_model\n",
    "                for pkl_file in os.scandir(env_dir):\n",
    "                    post_name = pkl_file.path.split(\"/\")[-1].split(\".\")[0]\n",
    "                    model_dict[algo][env_name][post_name] = ALGOS[algo].load(pkl_file.path, env=env, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dict[viz_algo][viz_env]['postprocess_default']\n",
    "#env = gym.make(viz_env, render=True)\n",
    "o,a,r,i = do_rollout_stable(env, model, render_wait=0.002, render=True, return_on_done=False, override_reset=False, num_steps=10000)\n",
    "print(len(r))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mujoco 1.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
