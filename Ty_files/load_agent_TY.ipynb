{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pybullet_envs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# import panda_gym # Not in requirements, required for panda envs, get latest from here: https://github.com/qgallouedec/panda-gym , don't use version from pypy \n",
    "\n",
    "from seagul.zoo3_utils import load_zoo_agent, ALGOS\n",
    "\n",
    "path_to_zoo = \"/home/asutay/Documents/rl-baselines3-zoo/\" # Very hacky but this is what we do for now. use: git clone --recursive https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "\n",
    "#model_dir = os.path.abspath('') + \"/keep_agents/bullet_works_rewards/\" # Bullet envs with mdim and cdim rewards\n",
    "#model_dir = os.path.abspath('') + \"/keep_agents/default_post_01_001/\" # Bullet with no extra reward, just policy refinement with ARS  \n",
    "model_dir = os.path.abspath('') + \"/keep_agents/train_all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ppo/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/policy_refinement/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/ddpg/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/tqc/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/a2c/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "Loading running average\n",
      "with params: {'norm_obs': True, 'norm_reward': True}\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/td3/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/AntBulletEnv-v0_1/AntBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/ReacherBulletEnv-v0_1/ReacherBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/HopperBulletEnv-v0_1/HopperBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/HalfCheetahBulletEnv-v0_1/HalfCheetahBulletEnv-v0\n",
      "/home/asutay/Documents/rl-baselines3-zoo//rl-trained-agents/sac/Walker2DBulletEnv-v0_1/Walker2DBulletEnv-v0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through save directory and load everything\n",
    "\n",
    "model_dict = {}\n",
    "env_dict = {}\n",
    "\n",
    "for algo_file in os.scandir(model_dir):\n",
    "    algo_dir = algo_file.path\n",
    "    algo = algo_dir.split(\"/\")[-1]\n",
    "    model_dict[algo] = {}\n",
    "    env_dict[algo] = {}\n",
    "    for env_file in os.scandir(algo_dir):\n",
    "        env_dir = env_file.path\n",
    "        env_name = env_dir.split(\"/\")[-1]\n",
    "        model_dict[algo][env_name] = {}\n",
    "        env_dict[algo][env_name] = {}\n",
    "        env, original_model = load_zoo_agent(env_name, algo, zoo_path = path_to_zoo)\n",
    "        env_dict[algo][env_name] = env\n",
    "        model_dict[algo][env_name]['original'] = original_model\n",
    "        for pkl_file in os.scandir(env_dir):\n",
    "            post_name = pkl_file.path.split(\"/\")[-1].split(\".\")[0]\n",
    "            model_dict[algo][env_name][post_name] = ALGOS[algo].load(pkl_file.path, env=env, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ppo', 'ddpg', 'tqc', 'a2c', 'td3', 'sac']\n",
      "['AntBulletEnv-v0', 'ReacherBulletEnv-v0', 'HopperBulletEnv-v0', 'HalfCheetahBulletEnv-v0', 'Walker2DBulletEnv-v0']\n",
      "['original', 'postprocess_default']\n"
     ]
    }
   ],
   "source": [
    "algo_list = list(model_dict.keys())\n",
    "env_list = list(model_dict[algo_list[0]].keys())\n",
    "post_list = list(model_dict[algo_list[0]][env_list[0]].keys())\n",
    "\n",
    "print(algo_list) # Original Algorithm\n",
    "print(env_list) # Environment\n",
    "\n",
    "# Postprocessor, autogenerated names. \"original\" means the original agent from zoo without additional training, \"postprocess_default\" means just ARS with not extra reward.\n",
    "# Any other name is some new reward functio \n",
    "print(post_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_dict['sac']['Walker2DBulletEnv-v0']\n",
    "model = model_dict['sac']['Walker2DBulletEnv-v0'][post_list[0]] #change to post_list[1] for postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from seagul.zoo3_utils import do_rollout_stable\n",
    "def do_rollout_mine(env, model, render=False, render_wait=0.01, seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    if seed:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Add push or something else here \n",
    "\n",
    "        state_list.append(np.copy(obs))\n",
    "        \n",
    "\n",
    "        actions,_ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        # Or maybe here\n",
    "\n",
    "    \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(render_wait)\n",
    "        \n",
    "        act_list.append(np.copy(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    state_arr = np.stack(state_list).squeeze()\n",
    "    act_arr = np.stack(act_list).squeeze()\n",
    "    \n",
    "    return state_arr, act_arr, reward_list, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,act,rew,info = do_rollout_mine(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2415.4558]\n",
      "[{'TimeLimit.truncated': True, 'episode': {'r': 2415.458528, 'l': 1000, 't': 82.058881}, 'terminal_observation': array([-3.23349327e-01,  0.00000000e+00,  1.00000000e+00,  3.44059169e-01,\n",
      "        0.00000000e+00, -2.47618160e-03,  0.00000000e+00, -7.08991587e-01,\n",
      "        3.16140801e-01,  2.12449670e-01,  7.62875527e-02, -3.03854495e-01,\n",
      "        2.74799526e-01, -1.20158382e-01,  6.17590904e-01, -2.45899245e-01,\n",
      "       -3.75985354e-02,  1.52041882e-01,  1.00792265e+00,  8.04062234e-04,\n",
      "        1.00000000e+00,  1.00000000e+00,  0.00000000e+00])}]\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(rew))\n",
    "print(info)\n",
    "print(type(info))\n",
    "type(info[0]['episode']['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env_dict['sac']['Walker2DBulletEnv-v0']\n",
    "model = model_dict['sac']['Walker2DBulletEnv-v0'][post_list[0]] #change to post_list[1] for postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-94c837a2df50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mn_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;31m#Trial number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_trial\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_rollout_mine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mep_rew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mep_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-b649597fd980>\u001b[0m in \u001b[0;36mdo_rollout_mine\u001b[0;34m(env, model, render, render_wait, seed)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Or maybe here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/policy_refinement/lib/python3.6/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/policy_refinement/lib/python3.6/site-packages/stable_baselines3/common/vec_env/vec_normalize.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Normalize the terminal observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Rollout Walker for no noise for n trials\n",
    "env_name = env_list[4]\n",
    "data_no_noise={}\n",
    "row = 0\n",
    "\n",
    "for k in enumerate(post_list):\n",
    "    #for j in enumerate(env_list):\n",
    "        for i in enumerate(algo_list):\n",
    "        \n",
    "            env = env_dict[i[1]][env_name]\n",
    "            model = model_dict[i[1]][env_name][k[1]] # no refinement\n",
    "            #model2 = model_dict[i[1]][j[1]][post_list[1]] # ARS policy refinement\n",
    "            count = 1\n",
    "            fail = 0\n",
    "            rewards_list = []\n",
    "            l_list = [] \n",
    "            n_trial = 300 #Trial number\n",
    "            while count <= n_trial :\n",
    "                obs,act,rew,info = do_rollout_mine(env, model)\n",
    "                ep_rew = info[0]['episode']['r']\n",
    "                ep_l = info[0]['episode']['l']\n",
    "\n",
    "                rewards_list.append(ep_rew)\n",
    "                l_list.append(ep_l)\n",
    "\n",
    "                rewards_arr = np.stack(rewards_list).squeeze()\n",
    "                l_arr = np.stack(l_list).squeeze()\n",
    "\n",
    "                if info[0]['episode']['l']<1000:\n",
    "                    fail+=1\n",
    "                count+=1\n",
    "            fail_percentage = 100*fail/n_trial\n",
    "\n",
    "            reward_mean = np.mean(rewards_arr)\n",
    "            reward_std = np.std(rewards_arr)\n",
    "            l_mean = np.mean(l_arr)\n",
    "#            if k[0] == 1:\n",
    "#                data_no_noise[str(row)] = data_no_noise[str(row)]+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#            else:\n",
    "#                data_no_noise[str(row)] = [j[1],i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            \n",
    "            data_no_noise[str(row)] = [k[1],env_name,i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            print(row)\n",
    "            row += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3333333333333335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env</th>\n",
       "      <th>algo</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>%fail</th>\n",
       "      <th>l_mean</th>\n",
       "      <th>r_mean_refined</th>\n",
       "      <th>r_std_refined</th>\n",
       "      <th>%fail_refined</th>\n",
       "      <th>l_mean_refined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2799.667353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2952.524329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>3488.584792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3638.116329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>3341.984081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3443.095194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AntBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>3114.575600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3246.050433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>25.185163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.965402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>8.856911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>16.417330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>11.155703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>9.163791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ReacherBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>8.638552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>35.280945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2616.276326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2643.144418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2677.904975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2661.941047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2698.035813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2846.292468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HopperBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2606.001282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2687.876353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2886.417895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2974.621163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>3645.962838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3740.017209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2796.377517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2941.194812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HalfCheetahBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2786.622450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2882.788853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2117.996360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2261.593541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2670.960741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2749.068124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2240.877771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2446.863895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2281.517374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2399.754676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        env algo       r_mean  r_std  %fail  l_mean  \\\n",
       "0           AntBulletEnv-v0  ppo  2799.667353    0.0    0.0  1000.0   \n",
       "1           AntBulletEnv-v0  tqc  3488.584792    0.0    0.0  1000.0   \n",
       "2           AntBulletEnv-v0  td3  3341.984081    0.0    0.0  1000.0   \n",
       "3           AntBulletEnv-v0  sac  3114.575600    0.0    0.0  1000.0   \n",
       "4       ReacherBulletEnv-v0  ppo    25.185163    0.0  100.0   150.0   \n",
       "5       ReacherBulletEnv-v0  tqc     8.856911    0.0  100.0   150.0   \n",
       "6       ReacherBulletEnv-v0  td3    11.155703    0.0  100.0   150.0   \n",
       "7       ReacherBulletEnv-v0  sac     8.638552    0.0  100.0   150.0   \n",
       "8        HopperBulletEnv-v0  ppo  2616.276326    0.0    0.0  1000.0   \n",
       "9        HopperBulletEnv-v0  tqc  2677.904975    0.0    0.0  1000.0   \n",
       "10       HopperBulletEnv-v0  td3  2698.035813    0.0    0.0  1000.0   \n",
       "11       HopperBulletEnv-v0  sac  2606.001282    0.0    0.0  1000.0   \n",
       "12  HalfCheetahBulletEnv-v0  ppo  2886.417895    0.0    0.0  1000.0   \n",
       "13  HalfCheetahBulletEnv-v0  tqc  3645.962838    0.0    0.0  1000.0   \n",
       "14  HalfCheetahBulletEnv-v0  td3  2796.377517    0.0    0.0  1000.0   \n",
       "15  HalfCheetahBulletEnv-v0  sac  2786.622450    0.0    0.0  1000.0   \n",
       "16     Walker2DBulletEnv-v0  ppo  2117.996360    0.0    0.0  1000.0   \n",
       "17     Walker2DBulletEnv-v0  tqc  2670.960741    0.0    0.0  1000.0   \n",
       "18     Walker2DBulletEnv-v0  td3  2240.877771    0.0    0.0  1000.0   \n",
       "19     Walker2DBulletEnv-v0  sac  2281.517374    0.0    0.0  1000.0   \n",
       "\n",
       "    r_mean_refined  r_std_refined  %fail_refined  l_mean_refined  \n",
       "0      2952.524329            0.0            0.0          1000.0  \n",
       "1      3638.116329            0.0            0.0          1000.0  \n",
       "2      3443.095194            0.0            0.0          1000.0  \n",
       "3      3246.050433            0.0            0.0          1000.0  \n",
       "4         1.965402            0.0          100.0           150.0  \n",
       "5        16.417330            0.0          100.0           150.0  \n",
       "6         9.163791            0.0          100.0           150.0  \n",
       "7        35.280945            0.0          100.0           150.0  \n",
       "8      2643.144418            0.0            0.0          1000.0  \n",
       "9      2661.941047            0.0            0.0          1000.0  \n",
       "10     2846.292468            0.0          100.0           994.0  \n",
       "11     2687.876353            0.0          100.0           996.0  \n",
       "12     2974.621163            0.0            0.0          1000.0  \n",
       "13     3740.017209            0.0            0.0          1000.0  \n",
       "14     2941.194812            0.0            0.0          1000.0  \n",
       "15     2882.788853            0.0            0.0          1000.0  \n",
       "16     2261.593541            0.0            0.0          1000.0  \n",
       "17     2749.068124            0.0            0.0          1000.0  \n",
       "18     2446.863895            0.0            0.0          1000.0  \n",
       "19     2399.754676            0.0            0.0          1000.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_no_noise['0'] = data_no_noise['0']+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#print(data_no_noise)\n",
    "import pandas as pd\n",
    "#df=pd.DataFrame.from_dict(data_no_noise, orient='index', columns=['env', 'algo', 'post', 'r_mean', 'r_std', '%fail', 'l_mean'])\n",
    "df_no_noise=pd.DataFrame.from_dict(data_no_noise, orient='index', columns=['env', 'algo', 'r_mean', 'r_std', '%fail', 'l_mean', 'r_mean_refined', 'r_std_refined', '%fail_refined', 'l_mean_refined'])\n",
    "path = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_no_noise.csv'\n",
    "df_no_noise.to_csv(path,index = False)\n",
    "\n",
    "df_no_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original ppo AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original sac AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original sac ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original sac HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original tqc HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original td3 HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original sac HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "original ppo Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "original tqc Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "original td3 Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "original sac Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default ppo AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac AntBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac ReacherBulletEnv-v0 [inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac HopperBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default tqc HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default td3 HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default sac HalfCheetahBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf  1.]\n",
      "postprocess_default ppo Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default tqc Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default td3 Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n",
      "postprocess_default sac Walker2DBulletEnv-v0 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf  1.]\n"
     ]
    }
   ],
   "source": [
    "for k in enumerate(post_list):\n",
    "    for j in enumerate(env_list):\n",
    "        for i in enumerate(algo_list):\n",
    "        \n",
    "            env = env_dict[i[1]][j[1]]\n",
    "            model = model_dict[i[1]][j[1]][k[1]]\n",
    "            a = env.observation_space.high\n",
    "            print(k[1],i[1],j[1],a)\n",
    "#print(.025*env.action_space.high)\n",
    "#print(.025*(env.action_space.high-env.action_space.low)/2)\n",
    "#np.random.normal(0,0.025,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define do_rollout with Gaussian noise added to the actions\n",
    "def do_rollout_noise_action(env, model, render=False, render_wait=0.01, seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    if seed:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    l = len(env.action_space.low)\n",
    "    \n",
    "    mean= 0 \n",
    "    std = .025 # actions are normalized between -1 and 1 for all envs so using a static std for noise\n",
    "    while not done:\n",
    "        # Add push or something else here \n",
    "\n",
    "        state_list.append(np.copy(obs))\n",
    "        \n",
    "\n",
    "        actions,_ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        \n",
    "        noise = np.reshape(np.random.normal(mean,std,l),(1,l))\n",
    "        actions += noise #add gaussian noise to actions\n",
    "        \n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        # Or maybe here\n",
    "\n",
    "    \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(render_wait)\n",
    "        \n",
    "        act_list.append(np.copy(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    state_arr = np.stack(state_list).squeeze()\n",
    "    act_arr = np.stack(act_list).squeeze()\n",
    "    \n",
    "    return state_arr, act_arr, reward_list, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define do_rollout with Gaussian noise on the observations\n",
    "def do_rollout_noise_obs(env, model, render=False, render_wait=0.01, seed=None):\n",
    "    state_list = []\n",
    "    act_list = []\n",
    "    reward_list = []\n",
    "\n",
    "    if seed:\n",
    "        env.seed(seed)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Add push or something else here \n",
    "\n",
    "        state_list.append(np.copy(obs))\n",
    "        \n",
    "\n",
    "        actions,_ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        mean = 0\n",
    "        std = 1 #to be determined per env\n",
    "        obs += numpy.random.normal(mean,std,1) #sample one value from Gaussian and add to obs\n",
    "        # Or maybe here\n",
    "\n",
    "    \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(render_wait)\n",
    "        \n",
    "        act_list.append(np.copy(actions))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "    state_arr = np.stack(state_list).squeeze()\n",
    "    act_arr = np.stack(act_list).squeeze()\n",
    "    \n",
    "    return state_arr, act_arr, reward_list, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run set number of trials and check fail/fall rate and mean rewards\n",
    "data_noise_action={}\n",
    "row = 0\n",
    "env_name = env_list[4]\n",
    "for k in enumerate(post_list):\n",
    "    #for j in enumerate(env_list):\n",
    "        for i in enumerate(algo_list):\n",
    "        \n",
    "            env = env_dict[i[1]][env_name]\n",
    "            model = model_dict[i[1]][env_name][k[1]] # no refinement\n",
    "            #model2 = model_dict[i[1]][j[1]][post_list[1]] # ARS policy refinement\n",
    "            count = 1\n",
    "            fail = 0\n",
    "            rewards_list = []\n",
    "            l_list = [] \n",
    "            n_trial = 100 #Trial number\n",
    "            while count <= n_trial :\n",
    "                obs,act,rew,info = do_rollout_noise_action(env, model)\n",
    "                ep_rew = info[0]['episode']['r']\n",
    "                ep_l = info[0]['episode']['l']\n",
    "\n",
    "                rewards_list.append(ep_rew)\n",
    "                l_list.append(ep_l)\n",
    "\n",
    "                rewards_arr = np.stack(rewards_list).squeeze()\n",
    "                l_arr = np.stack(l_list).squeeze()\n",
    "\n",
    "                if info[0]['episode']['l']<1000:\n",
    "                    fail+=1\n",
    "                count+=1\n",
    "            fail_percentage = 100*fail/n_trial\n",
    "\n",
    "            reward_mean = np.mean(rewards_arr)\n",
    "            reward_std = np.std(rewards_arr)\n",
    "            l_mean = np.mean(l_arr)\n",
    "#            if k[0] == 1:\n",
    "#                data_no_noise[str(row)] = data_no_noise[str(row)]+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#            else:\n",
    "#                data_no_noise[str(row)] = [j[1],i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            \n",
    "            data_noise_action[str(row)] = [k[1],env_name,i[1],reward_mean,reward_std,fail_percentage,l_mean]\n",
    "            row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>env</th>\n",
       "      <th>algo</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>%fail</th>\n",
       "      <th>l_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2105.509806</td>\n",
       "      <td>15.345420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2517.398869</td>\n",
       "      <td>567.820513</td>\n",
       "      <td>7.0</td>\n",
       "      <td>944.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2228.219013</td>\n",
       "      <td>111.098149</td>\n",
       "      <td>12.0</td>\n",
       "      <td>994.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2264.467164</td>\n",
       "      <td>227.833899</td>\n",
       "      <td>3.0</td>\n",
       "      <td>988.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2219.476561</td>\n",
       "      <td>273.200808</td>\n",
       "      <td>3.0</td>\n",
       "      <td>980.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2744.322199</td>\n",
       "      <td>7.325113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2444.182995</td>\n",
       "      <td>7.772026</td>\n",
       "      <td>6.0</td>\n",
       "      <td>999.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2401.658417</td>\n",
       "      <td>13.947507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  post                   env algo       r_mean       r_std  \\\n",
       "0             original  Walker2DBulletEnv-v0  ppo  2105.509806   15.345420   \n",
       "1             original  Walker2DBulletEnv-v0  tqc  2517.398869  567.820513   \n",
       "2             original  Walker2DBulletEnv-v0  td3  2228.219013  111.098149   \n",
       "3             original  Walker2DBulletEnv-v0  sac  2264.467164  227.833899   \n",
       "4  postprocess_default  Walker2DBulletEnv-v0  ppo  2219.476561  273.200808   \n",
       "5  postprocess_default  Walker2DBulletEnv-v0  tqc  2744.322199    7.325113   \n",
       "6  postprocess_default  Walker2DBulletEnv-v0  td3  2444.182995    7.772026   \n",
       "7  postprocess_default  Walker2DBulletEnv-v0  sac  2401.658417   13.947507   \n",
       "\n",
       "   %fail   l_mean  \n",
       "0    0.0  1000.00  \n",
       "1    7.0   944.94  \n",
       "2   12.0   994.84  \n",
       "3    3.0   988.48  \n",
       "4    3.0   980.99  \n",
       "5    0.0  1000.00  \n",
       "6    6.0   999.85  \n",
       "7    0.0  1000.00  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_no_noise['0'] = data_no_noise['0']+[reward_mean,reward_std,fail_percentage,l_mean]\n",
    "#print(data_no_noise)\n",
    "import pandas as pd\n",
    "df=pd.DataFrame.from_dict(data_noise_action, orient='index', columns=[ 'post', 'env', 'algo', 'r_mean', 'r_std', '%fail', 'l_mean'])\n",
    "#df=pd.DataFrame.from_dict(data_noise_action, orient='index', columns=['env', 'algo', 'r_mean', 'r_std', '%fail', 'l_mean', 'r_mean_refined', 'r_std_refined', '%fail_refined', 'l_mean_refined'])\n",
    "path = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_noise_2_5_pct.csv'\n",
    "df.to_csv(path,index = False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>env</th>\n",
       "      <th>algo</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>%fail</th>\n",
       "      <th>l_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2105.51±15.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2517.4±567.82</td>\n",
       "      <td>7.0</td>\n",
       "      <td>944.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2228.22±111.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>994.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2264.47±227.83</td>\n",
       "      <td>3.0</td>\n",
       "      <td>988.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>2219.48±273.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>980.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>tqc</td>\n",
       "      <td>2744.32±7.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>td3</td>\n",
       "      <td>2444.18±7.77</td>\n",
       "      <td>6.0</td>\n",
       "      <td>999.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>postprocess_default</td>\n",
       "      <td>Walker2DBulletEnv-v0</td>\n",
       "      <td>sac</td>\n",
       "      <td>2401.66±13.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  post                   env algo          r_mean  %fail  \\\n",
       "0             original  Walker2DBulletEnv-v0  ppo   2105.51±15.35    0.0   \n",
       "1             original  Walker2DBulletEnv-v0  tqc   2517.4±567.82    7.0   \n",
       "2             original  Walker2DBulletEnv-v0  td3   2228.22±111.1   12.0   \n",
       "3             original  Walker2DBulletEnv-v0  sac  2264.47±227.83    3.0   \n",
       "4  postprocess_default  Walker2DBulletEnv-v0  ppo   2219.48±273.2    3.0   \n",
       "5  postprocess_default  Walker2DBulletEnv-v0  tqc    2744.32±7.33    0.0   \n",
       "6  postprocess_default  Walker2DBulletEnv-v0  td3    2444.18±7.77    6.0   \n",
       "7  postprocess_default  Walker2DBulletEnv-v0  sac   2401.66±13.95    0.0   \n",
       "\n",
       "    l_mean  \n",
       "0  1000.00  \n",
       "1   944.94  \n",
       "2   994.84  \n",
       "3   988.48  \n",
       "4   980.99  \n",
       "5  1000.00  \n",
       "6   999.85  \n",
       "7  1000.00  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV from path and format it to merge mean and std \n",
    "# The column names need to be changed according to CSV\n",
    "path_csv = '~/Documents/GitHub/policy_refinement/Ty_files/Ty_csv/walker_noise_2_5_pct.csv'\n",
    "# read csv at path and change the data type of specific columns for rounding\n",
    "df = pd.read_csv(path_csv,index_col=False, dtype =  {'post':str, 'env':str, 'algo':str, 'r_mean':np.double, \n",
    "                                    'r_std':np.double, '%fail':np.double, 'l_mean':np.double} )\n",
    "#df_test = (df.groupby(df.columns[3], axis=1).apply(lambda x: x.astype(str).apply('±'.join, 1)))\n",
    "df_test = df\n",
    "df_test=df_test.round({'r_mean':2,'r_std':2,'%fail':2,'l_mean':2})\n",
    "\n",
    "#merge mean and std with plusminus from this point on the column is type str\n",
    "df_test['r_mean'] = df_test[['r_mean', 'r_std']].astype(str).agg('±'.join, axis=1) \n",
    "\n",
    "#get rid of the std column\n",
    "df_test = df_test.drop('r_std',axis=1)\n",
    "df_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\usepackage{booktabs}\n",
      "\\begin{tabular}{llllrr}\n",
      "\\toprule\n",
      "                post &                   env & algo &          r\\_mean &  \\%fail &   l\\_mean \\\\\n",
      "\\midrule\n",
      "            original &  Walker2DBulletEnv-v0 &  ppo &   2105.51±15.35 &    0.0 &  1000.00 \\\\\n",
      "            original &  Walker2DBulletEnv-v0 &  tqc &   2517.4±567.82 &    7.0 &   944.94 \\\\\n",
      "            original &  Walker2DBulletEnv-v0 &  td3 &   2228.22±111.1 &   12.0 &   994.84 \\\\\n",
      "            original &  Walker2DBulletEnv-v0 &  sac &  2264.47±227.83 &    3.0 &   988.48 \\\\\n",
      " postprocess\\_default &  Walker2DBulletEnv-v0 &  ppo &   2219.48±273.2 &    3.0 &   980.99 \\\\\n",
      " postprocess\\_default &  Walker2DBulletEnv-v0 &  tqc &    2744.32±7.33 &    0.0 &  1000.00 \\\\\n",
      " postprocess\\_default &  Walker2DBulletEnv-v0 &  td3 &    2444.18±7.77 &    6.0 &   999.85 \\\\\n",
      " postprocess\\_default &  Walker2DBulletEnv-v0 &  sac &   2401.66±13.95 &    0.0 &  1000.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints the data from in Latex format\n",
    "print(\"\\\\usepackage{booktabs}\\n\"+ df_test.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (policy_refinement)",
   "language": "python",
   "name": "policy_refinement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
